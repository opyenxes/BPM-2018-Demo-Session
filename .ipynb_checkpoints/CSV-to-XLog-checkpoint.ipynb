{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL;DR\n",
    "This notebook shows how create an event log in XES format from a csv where each row is an event. Due to the full implementation, one can also add classifier and extensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load /home/jonathan/.ipython/profile_default/startup/01-setup.py\n",
    "# start up settings for jupyter notebook\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, sys\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['font.size'] = 15.0\n",
    "plt.rcParams['axes.labelsize'] = 15.0\n",
    "plt.rcParams['xtick.labelsize'] = 15.0\n",
    "plt.rcParams['ytick.labelsize'] = 15.0\n",
    "plt.rcParams['legend.fontsize'] = 15.0\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# set the max column width\n",
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "# to avoid have warnings from chained assignments\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import event data in CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_fp = './data/BPIC2012.csv'\n",
    "\n",
    "['caseid' 'org:resource' 'lifecycle:transition' 'concept:name'\n",
    " 'time:timestamp']\n",
    "\n",
    "dtypes = {\n",
    "    'caseid': str,\n",
    "    'trace:concept:name': str,\n",
    "    'trace:REG_DATE': str,\n",
    "    'trace:AMOUNT_REQ': int,\n",
    "    'event:org:resource': str,\n",
    "    'event:lifecycle:transition': str,\n",
    "    'event:concept:name': str,\n",
    "    'event:time:timestamp': str\n",
    "}\n",
    "\n",
    "log_df = pd.read_csv(csv_fp, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trace:REG_DATE</th>\n",
       "      <th>trace:concept:name</th>\n",
       "      <th>trace:AMOUNT_REQ</th>\n",
       "      <th>caseid</th>\n",
       "      <th>event:org:resource</th>\n",
       "      <th>event:lifecycle:transition</th>\n",
       "      <th>event:concept:name</th>\n",
       "      <th>event:time:timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>173688</td>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>173688</td>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.880000+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>173688</td>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-10-01 00:39:37.906000+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>173688</td>\n",
       "      <td>112</td>\n",
       "      <td>SCHEDULE</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 00:39:38.875000+02:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>173688</td>\n",
       "      <td>NaN</td>\n",
       "      <td>START</td>\n",
       "      <td>W_Completeren aanvraag</td>\n",
       "      <td>2011-10-01 11:36:46.437000+02:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     trace:REG_DATE trace:concept:name  trace:AMOUNT_REQ  \\\n",
       "0  2011-10-01 00:38:44.546000+02:00             173688             20000   \n",
       "1  2011-10-01 00:38:44.546000+02:00             173688             20000   \n",
       "2  2011-10-01 00:38:44.546000+02:00             173688             20000   \n",
       "3  2011-10-01 00:38:44.546000+02:00             173688             20000   \n",
       "4  2011-10-01 00:38:44.546000+02:00             173688             20000   \n",
       "\n",
       "   caseid event:org:resource event:lifecycle:transition  \\\n",
       "0  173688                112                   COMPLETE   \n",
       "1  173688                112                   COMPLETE   \n",
       "2  173688                112                   COMPLETE   \n",
       "3  173688                112                   SCHEDULE   \n",
       "4  173688                NaN                      START   \n",
       "\n",
       "       event:concept:name              event:time:timestamp  \n",
       "0             A_SUBMITTED  2011-10-01 00:38:44.546000+02:00  \n",
       "1       A_PARTLYSUBMITTED  2011-10-01 00:38:44.880000+02:00  \n",
       "2           A_PREACCEPTED  2011-10-01 00:39:37.906000+02:00  \n",
       "3  W_Completeren aanvraag  2011-10-01 00:39:38.875000+02:00  \n",
       "4  W_Completeren aanvraag  2011-10-01 11:36:46.437000+02:00  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opyenxes.factory.XFactory import XFactory\n",
    "from opyenxes.extension.XExtensionManager import XExtensionManager\n",
    "from opyenxes.extension.XExtension import XExtension\n",
    "from opyenxes.classification.XEventAndClassifier import XEventAndClassifier\n",
    "from opyenxes.classification.XEventLifeTransClassifier import XEventLifeTransClassifier\n",
    "from opyenxes.classification.XEventNameClassifier import XEventNameClassifier\n",
    "from opyenxes.classification.XEventResourceClassifier import XEventResourceClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter event related attributes\n",
    "event_attrib_names = list(filter(lambda val: 'event:' in val, log_df.columns))\n",
    "trace_attrib_names = list(filter(lambda val: 'trace:' in val, log_df.columns))\n",
    "\n",
    "# need to keep the special caseid column to connect events to traces\n",
    "event_attrib_names = ['caseid'] + event_attrib_names\n",
    "trace_attrib_names = ['caseid'] + trace_attrib_names\n",
    "\n",
    "# separate trace attributes from event attributes\n",
    "trace_df = log_df[trace_attrib_names].drop_duplicates()\n",
    "event_df = log_df[event_attrib_names]\n",
    "\n",
    "# removed the prefixes\n",
    "trace_df.columns = ['caseid'] + [val.replace('trace:', '') for val in trace_attrib_names[1:]]\n",
    "event_df.columns = ['caseid'] + [val.replace('event:', '') for val in event_attrib_names[1:]]\n",
    "\n",
    "# convert timestamps\n",
    "trace_df['REG_DATE'] = trace_df['REG_DATE'].astype(np.datetime64)\n",
    "event_df['time:timestamp'] = event_df['time:timestamp'].astype(np.datetime64)\n",
    "\n",
    "# make sure resource id gets read properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Event attributes: ['caseid' 'org:resource' 'lifecycle:transition' 'concept:name'\n",
      " 'time:timestamp']\n",
      "\n",
      "Trace attributes: ['caseid' 'REG_DATE' 'concept:name' 'AMOUNT_REQ']\n"
     ]
    }
   ],
   "source": [
    "print('Event attributes: {}\\n'.format(event_df.columns.values))\n",
    "print('Trace attributes: {}'.format(trace_df.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map between attribute names to create_attribute_X\n",
    "trace_attrib_to_factory = {\n",
    "    'REG_DATE': XFactory.create_attribute_timestamp,\n",
    "    'concept:name': XFactory.create_attribute_literal,\n",
    "    'AMOUNT_REQ': XFactory.create_attribute_discrete\n",
    "}\n",
    "\n",
    "event_attrib_to_factory = {\n",
    "    'org:resource': XFactory.create_attribute_literal,\n",
    "    'lifecycle:transition': XFactory.create_attribute_literal,\n",
    "    'concept:name': XFactory.create_attribute_literal,\n",
    "    'time:timestamp': XFactory.create_attribute_timestamp\n",
    "}\n",
    "\n",
    "\n",
    "def get_extension(attrib_name):\n",
    "    str_segments = attrib_name.split(':')\n",
    "    \n",
    "    if len(str_segments) < 2:\n",
    "        return None\n",
    "    \n",
    "    prefix = str_segments[0]\n",
    "    extension = XExtensionManager().get_by_prefix(prefix)\n",
    "    return extension\n",
    "    \n",
    "\n",
    "def create_attribute(attrib, attrib_type, attrib_to_factory_map, extensions):\n",
    "    factory_method = attrib_to_factory_map[attrib_type]\n",
    "    \n",
    "    # add extension to the attribute\n",
    "    extension = None\n",
    "    if ':' in attrib_type:\n",
    "        extension = get_extension(attrib_type)\n",
    "\n",
    "        assert isinstance(extension, XExtension), \\\n",
    "            'Extension is a {}'.format(str(type(extension)))\n",
    "\n",
    "        extensions.add(extension)\n",
    "    \n",
    "    # create xattribute\n",
    "    xattrib = factory_method(attrib_type, attrib, extension)\n",
    "    \n",
    "    return xattrib\n",
    "\n",
    "    \n",
    "def convert_event_row_to_xevent(event_attrib_types, event_row, extensions):\n",
    "    attrib_map = XFactory.create_attribute_map()\n",
    "    \n",
    "    for ind in range(len(event_row)):\n",
    "        attrib = event_row[ind]\n",
    "        attrib_type = event_attrib_types[ind]\n",
    "        \n",
    "        xattrib = create_attribute(attrib, attrib_type,\n",
    "                                   event_attrib_to_factory,\n",
    "                                   extensions)\n",
    "        \n",
    "        # add attribute to attribute map\n",
    "        attrib_map[xattrib.get_key()] = xattrib\n",
    "        \n",
    "    return XFactory.create_event(attrib_map)\n",
    "\n",
    "\n",
    "def create_trace(trace_attrib_types, trace_row, \n",
    "                 event_attrib_types, event_df,\n",
    "                 extensions):\n",
    "    # assume that the event_rows are related to the trace and \n",
    "    # that there is no caseid column\n",
    "    \n",
    "    # need to add the trace attributes\n",
    "    attrib_map = XFactory.create_attribute_map()\n",
    "    \n",
    "    for ind in range(len(trace_row)):\n",
    "        attrib = trace_row[ind]\n",
    "        attrib_type = trace_attrib_types[ind]\n",
    "        \n",
    "        xattrib = create_attribute(attrib, attrib_type, \n",
    "                                   trace_attrib_to_factory,\n",
    "                                   extensions)\n",
    "        \n",
    "        # add attribute to attribute map\n",
    "        attrib_map[xattrib.get_key()] = xattrib\n",
    "        \n",
    "    xtrace = XFactory.create_trace(attrib_map)\n",
    "    \n",
    "    # now add the events\n",
    "    for row in event_df.iterrows():\n",
    "        event_row = [row[1][key] for key in event_attrib_types]\n",
    "        xevent = convert_event_row_to_xevent(event_attrib_types, \n",
    "                                             event_row, extensions)\n",
    "        xtrace.append(xevent)\n",
    "        \n",
    "    return xtrace\n",
    "\n",
    "\n",
    "def create_xlog(trace_df, event_df):\n",
    "    xlog = XFactory.create_log()\n",
    "    \n",
    "    # iterate through trace rows\n",
    "    trace_attrib_types = list(filter(\n",
    "        lambda val: val != 'caseid', trace_df.columns\n",
    "    ))\n",
    "    \n",
    "    event_attrib_types = list(filter(\n",
    "        lambda val: val != 'caseid', event_df.columns\n",
    "    ))\n",
    "\n",
    "    extensions = set()\n",
    "    \n",
    "    for row in trace_df.iterrows():\n",
    "        trace_row = [row[1][key] for key in trace_attrib_types]\n",
    "                \n",
    "        # get the events that are related to this trace\n",
    "        caseid = row[1]['caseid']\n",
    "        \n",
    "#         print('Creating XTrace with caseid: {}'.format(caseid))\n",
    "        \n",
    "        events = event_df[(event_df['caseid'] == caseid)]\n",
    "        \n",
    "        xtrace = create_trace(trace_attrib_types, trace_row,\n",
    "                             event_attrib_types, events, extensions)\n",
    "        \n",
    "        xlog.append(xtrace)\n",
    "        \n",
    "    # add the used extensions\n",
    "    for ext in extensions:\n",
    "        xlog.get_extensions().add(ext)\n",
    "        \n",
    "    # create a classifier that classifies using activity and lifecycle\n",
    "    activity_clf = XEventNameClassifier()\n",
    "    lifecycle_clf = XEventLifeTransClassifier()\n",
    "    activity_lifecycle_clf = XEventAndClassifier([activity_clf, \n",
    "                                                  lifecycle_clf])\n",
    "    activity_lifecycle_clf.set_name('Activity classifier')\n",
    "    resource_clf = XEventResourceClassifier()\n",
    "    resource_clf.set_name('Resource classifier')\n",
    "    \n",
    "    xlog.get_classifiers().append(activity_lifecycle_clf)\n",
    "    xlog.get_classifiers().append(resource_clf)\n",
    "        \n",
    "    return xlog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a XLog with 200 traces\n"
     ]
    }
   ],
   "source": [
    "# make an event log of 100 traces\n",
    "trace_df_200 = trace_df.iloc[:200, :]\n",
    "\n",
    "print('Creating a XLog with {} traces'.format(trace_df_200.shape[0]))\n",
    "\n",
    "xlog = create_xlog(trace_df_200, event_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opyenxes.data_out.XesXmlGZIPSerializer import XesXmlGZIPSerializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importance: DEBUG\n",
      "Message: Start serializing log to XES.XML\n",
      "\n",
      "Importance: DEBUG\n",
      "Message: finished serializing log (605.481689453125 msec.)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# save the log in XES format\n",
    "xlog_fp = './data/BPIC2012-200.xes.gz'\n",
    "\n",
    "with open(xlog_fp, 'w') as f:\n",
    "    XesXmlGZIPSerializer().serialize(xlog, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bpm-demo-opyenxes)",
   "language": "python",
   "name": "bpm-demo-opyenxes"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
